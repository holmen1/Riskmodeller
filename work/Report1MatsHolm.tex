\documentclass[11pt]{article}
%\usepackage{geometry}                % See geometry.pdf to learn the layout options. There are lots.
\usepackage[a4paper,hmargin=3cm,vmargin=5cm]{geometry}
%\geometry{a4paper}                   % ... or a4paper or a5paper or ... 
%\geometry{landscape}                % Activate for for rotated page geometry
%\usepackage[parfill]{parskip}    % Activate to begin paragraphs with an empty line rather than an indent
\usepackage{graphicx}
\usepackage{amssymb, amsmath}
\usepackage{epstopdf}
\usepackage{float}
\DeclareGraphicsRule{.tif}{png}{.png}{`convert #1 `dirname #1`/`basename #1 .tif`.png}

\title{Report I - MT7027 Risk Models and Reserving in Non-Life Insurance}
\author{Mats Holm nnnnnn-nnnn }
\date{8 March, 2019}                                           % Activate to display a given date or no date

\begin{document}
\maketitle
\section*{Project I}
\subsection*{Objectives}

In this project we analyze claim
arrival times and claim size distributions for two insurance products.
The task is to model
the distribution of the total claim cost for claim arrivals from today until one year from
today. We have 10 years of data from two non-life branches. The goal is then to form two processes of the total claim amount,

\begin{align} \label{eq:sum1}
	S_1 = \sum_{k=1}^{N_1}  X_k 
\end{align}
and
\begin{align} \label{eq:sum2}
	 S_2 = \sum_{k=1}^{N_2} Y_k,
\end{align}

where $N_i$ will be modelled as non-homogenous Poisson processes, $X$ and $Y$ with something else. We will try to capture the dependence between
$S_1$ and $S_2$ by  either the
bootstraping method or with a Gaussian copula.

%With cumulative distribution of $S = S_1 + S_2$ find
%\begin{align*}
%	  \mathrm{P}\left(S < s \right). 
%\end{align*}

%%% CLAIM ARRIVAL
\subsection*{Claim arrival process}
By labeling each ClaimDay between 1-365 and plot the histogram we see in Figure \ref{fig:samplefig1} that both ClaimTypes show a common decrease during 'summer'.
 \begin{figure}[H]
 \center
  \includegraphics[scale=.5]{histyear.png}
  \caption{Summer slowdown}
  \label{fig:samplefig1}
\end{figure}

This requires an inhomogenuos process. In $N_t  \sim  \mathrm{Pois}(\mu(t))$, where  $\mu(t) = \lambda t$. We get from R $fitdistr$

%\begin{align}\label{eq:N}
%	N_t  \sim  \mathrm{Pois}(\mu(t))
%\end{align}
%In \eqref{eq:N} we chose $\mu(t) = \lambda t$. With $\lambda$ for different claim types and season. Found with the help of R $fitdistr$-function.


\begin{table}[!ht]
\center
\begin{tabular}{r|rr}
Type & Winter & Summer \\ 
\hline
1 & $\lambda=$10.9 & $\lambda=$3.06 \\
2 & $\lambda=$6.77 & $\lambda=$2.1\\
\hline
\end{tabular}
\caption{Sample table. Use informative captions.} \label{tab:sampletab}
\end{table}




%%% CLAIM COST
\subsection*{Claim cost}
First,  we see in Figure \ref{fig:samplefig2} we see that both ClaimTypes show no apparent seasonal variation.
 \begin{figure}[H]
 \center
  \includegraphics[scale=.5]{meancost.png}
  \caption{Daily meancost}
  \label{fig:samplefig2}
\end{figure}

Without to much analysis we chose lognormal for
ClaimType 1
\begin{align}\label{eq:N}
	f_{X}(x) = \dfrac{1}{\sqrt{2\pi}\sigma x} \exp\left(-\dfrac{(\log x - \mu)^2}{2\sigma^2}\right) , 
\end{align}
for all i.i.d. $X_k$ in (\ref{eq:sum1}).

And Weibull for
ClaimType 2
\begin{align}\label{eq:N}
	f_{Y}(y) = c \tau y^{\tau - 1}e^{-cy^\tau} , 
\end{align}
for all i.i.d. $Y_k$ in (\ref{eq:sum2}).

With values in \ref{tab:cost}
\begin{table}[!ht]
\center
\begin{tabular}{|r|rr|}
\hline
1 LogNorm & $\mu log=$10.08248 ,& $\sigma log=$0.3247564 \\
2 Weibull & $\tau=$1.148278 ,& $c=$105523\\
\hline
\end{tabular}
\caption{Sample table} \label{tab:cost}
\end{table}


we show the fit Figure \ref{fig:samplefig3}. No too good fit, which we will study with help of qq-plots below.


 \begin{figure}[H]
 \center
  \includegraphics[scale=.5]{histfit.png}
  \label{fig:samplefig3}
\end{figure}


QQ-plot showing, see fig \ref{fig:qqplot}

 \begin{figure}[H]
 \center
  \includegraphics[scale=.5]{qqplot.png}
  \caption{QQ-plot}
  \label{fig:qqplot}
\end{figure}

Underestimation of right tail see fig \ref{fig:fit}

 \begin{figure}[H]
 \center
  \includegraphics[scale=.5]{lognormalhistfit.png}
  \caption{Fat tails}
  \label{fig:fit}
\end{figure}


With these assumptions we can 
 create random samples of a yearly cost by

First $\hat{N} <-  sum(rpois(lambdaw,winterdays)) +  sum(rpois(lambdas,summerdays))$
which we use in

then
\begin{align*} 
	\hat{X} <- rlnorm(\hat{N}_1,\mu log,\sigma log) 
\end{align*}
and
\begin{align*} 
	 \hat{Y} <- rweibull(\hat{N}_2,\tau,c)
\end{align*}


then we model total claim cost after one year by
\begin{align} \label{eq:sum1}
	\hat{S_1} = \sum_{k=1}^{\hat{N}_1} \hat{ X}_k   
\end{align}
and
\begin{align} \label{eq:sum2}
	 \hat{S_2} = \sum_{k=1}^{\hat{N}_2} \hat{Y}_k
\end{align}


\subsection*{Dependence}
Before creating cumulative distribution, we check dependence between historical data
 Figure \ref{fig:samplefig4} showing dependence.


 \begin{figure}[H]
 \center
  \includegraphics[height=8cm, width=10cm]{rhodaily.png}
  \caption{Daily cost 10Y}
  \label{fig:samplefig4}
\end{figure}

 \begin{figure}[H]
 \center
  \includegraphics[height=8cm, width=10cm]{rhoyearly.png}
  \caption{Yearly cost 10Y}
  \label{fig:samplefig10y}
\end{figure}



%%% CUMULATIVE
\subsection*{Bivariate total claims cost}

%% Bootstrap
\subsubsection*{Bootstrap}


 \begin{figure}[H]
 \center
  \includegraphics[height=8cm, width=10cm]{wintersummer.png}
  \caption{Yearly cost 10Y}
  \label{fig:season}
\end{figure}

 \begin{figure}[H]
 \center
  \includegraphics[height=8cm, width=10cm]{bs.png}
  \caption{Yearly cost 10Y}
  \label{fig:season}
\end{figure}

%% Copula
\subsubsection*{Copula}
With the help of R 
First create normar bivariate $Z_1,Z_2$.
\begin{align} \label{eq:bi1}
	 \begin{bmatrix} Z_1 \\ Z_2\end{bmatrix} \sim N\left(\begin{bmatrix} 0 \\ 0\end{bmatrix},\begin{bmatrix} 1&\rho \\ \rho&1\end{bmatrix}\right)
\end{align}
then from   $\left(\Phi(Z_1),\Phi(Z_2)\right) \sim  U[0,1] \times U[0,1]$ .
With $\hat{F}_1^\leftharpoonup$ and $\hat{F}_2^\leftharpoonup$ the inverse empirical cdf from $\hat{S_1}$ and $\hat{S_2}$ respectively.
We get
\begin{align} \label{eq:bi3}
	  \left(\tilde{S_1},\tilde{S_2}\right) = \left(\hat{F}_X^\leftharpoonup(\Phi(Z_1)),\hat{F}_Y^\leftharpoonup(\Phi(Z_2))\right) 
\end{align}
a Gaussian copula $ \left(\tilde{S_1},\tilde{S_2}\right)$!

 \begin{figure}[H]
 \center
  \includegraphics[scale=0.8]{pairs5.png}
  \caption{Gaussian Copula}
  \label{fig:samplefig5}
\end{figure}

\subsection*{XL covers}

\subsection*{SL covers}

%%% STOPLOSS
\subsection*{SL cover}
Let
\begin{align*} 
	\tilde{S}= \tilde{S_1} + \tilde{S_2}
\end{align*}
model total cost.

Then, with ... we find the 10\%-quantile
\begin{align*} 
	K = \hat{F}_{12}^\leftharpoonup(0.9)
\end{align*}
where $\hat{F}_{12}^\leftharpoonup$ is the inverse empirical cdf for $\tilde{S}$  formed from copula $(\tilde{S_1}, \tilde{S_2})$.

\begin{align} \label{eqsl1}
	R_{SL} = \dfrac{1}{N}\sum_{n=1}^N\left(	 \tilde{S}^{(n)}-K\right)_+        
\end{align}
and then price $\pi = 1.1R_{SL} = 18,507,884$.

\subsection*{Summary}
({\it Lacking analysis, calibration and consistency checks. Focused on coverage... })



\section*{Appendix}

\begin{verbatim}
## Risk och reserv Projekt 1

library(MASS)

claims <- read.table("Projekt1_Grupp8.txt", header = TRUE, sep = ";")
summary(claims)
head(claims, n=10)

arrivals.daily <- aggregate(list(Arrivals=claims$ClaimDay),
                            list(ClaimDay=claims$ClaimDay, ClaimType=claims$ClaimType),
                            length)
cost.daily <- aggregate(list(Cost=claims$ClaimCost),
                        list(ClaimDay=claims$ClaimDay, ClaimType=claims$ClaimType), sum)

claims.daily<-merge(arrivals.daily,cost.daily)

claims.365<-subset(claims, select=c("ClaimType","ClaimDay"))
# Label to days in 1 Y 1-365
claims.365$ClaimDay365 <- claims.365$ClaimDay %% 365
claims.365$ClaimDay365[claims.365$ClaimDay365==0] <- 365

claims.daily$MeanCost<-claims.daily$Cost/claims.daily$Arrivals

## ARRIVALS

# Histogram 1Y dividided by 12 months
par(mfrow=c(2,1))
h1 <- claims.365$ClaimDay365[claims.365$ClaimType==1]
b1 <- seq(min(h1), max(h1), length.out = 13)
hist(h1, breaks=b1)
h2 <- claims.365$ClaimDay365[claims.365$ClaimType==2]
b2 <- seq(min(h2), max(h2), length.out = 13)
hist(h2, breaks=b2)

# From hist, less arrivals June-August
# Label to days in 1 Y 1-365
claims.daily$ClaimDay365 <- claims.daily$ClaimDay %% 365
claims.daily$ClaimDay365[claims.daily$ClaimDay365==0] <- 365

claims.daily$Summer <- 0
claims.daily$Summer[b1[5]<claims.daily$ClaimDay365&claims.daily$ClaimDay365<=b1[9]] <-1

# Branch 1
lambda1s<-fitdistr(claims.daily$Arrivals[claims.daily$ClaimType==1 &
                   claims.daily$Summer==1], "Poisson")$estimate
lambda1w<-fitdistr(claims.daily$Arrivals[claims.daily$ClaimType==1 &
                   claims.daily$Summer==0], "Poisson")$estimate
# Branch 2
lambda2s<-fitdistr(claims.daily$Arrivals[claims.daily$ClaimType==2 &
                   claims.daily$Summer==1], "Poisson")$estimate
lambda2w<-fitdistr(claims.daily$Arrivals[claims.daily$ClaimType==2 &
                   claims.daily$Summer==0],"Poisson")$estimate

### COST
par(mfrow=c(2,1))
plot(claims.daily$ClaimDay[claims.daily$ClaimType==1],
     claims.daily$MeanCost[claims.daily$ClaimType==1])
plot(claims.daily$ClaimDay[claims.daily$ClaimType==2],
     claims.daily$MeanCost[claims.daily$ClaimType==2])

par(mfrow=c(2,1))
hist(claims.daily$MeanCost[claims.daily$ClaimType==1],100)
hist(claims.daily$MeanCost[claims.daily$ClaimType==2],100)

# Empirisk fÃ¶rdelningsfunktion
par(mfrow=c(2,1))
plot(ecdf(claims.daily$MeanCost[claims.daily$ClaimType==1]))
plot(ecdf(claims.daily$MeanCost[claims.daily$ClaimType==2]))

# Claims 1
summary(claims.daily$MeanCost[claims.daily$ClaimType==1])
x1<-claims.daily$MeanCost[claims.daily$ClaimType==1]
hist(x1,freq=F)
fit1<-fitdistr(x1,"lognormal")$estimate
lines(dlnorm(0:max(x1),fit1[1],fit1[2]),lwd=3)

# Claims 2
summary(claims.daily$MeanCost[claims.daily$ClaimType==2])
x2<-claims.daily$MeanCost[claims.daily$ClaimType==2]
hist(x2,freq=F)
fit2<-fitdistr(x2,"weibull")$estimate
#fit2<-fitdistr(x,"weibull",list(shape = 10000, scale = 10), lower = 50)$estimate
lines(dweibull(min(x2):max(x2),fit2[1],fit2[2]),lwd=3)


### Compound
months<-c(31,28,31,30,31,30,31,31,30,31,30,31)
summer<-sum(months[5:8])
winter<-sum(months[1:4])+sum(months[9:12])
runs<-10000
S<-matrix(0,runs,2)
for (k in 1:runs)
{
  # Branch 1 lognormal claims
  N1w<-sum(rpois(lambda1w,winter))
  N1s<-sum(rpois(lambda1s,summer))
  N1<-N1w+N1s
  Y1<-rlnorm(N1,fit1[1],fit1[2])
  S[k,1]<-sum(Y1)
  
  # Branch 2 Weibull claims
  N2w<-sum(rpois(lambda2w,winter))
  N2s<-sum(rpois(lambda2s,summer))
  N2<-N2w+N2s
  Y2<-rweibull(N2,fit2[1],fit2[2])
  S[k,2]<-sum(Y2)
}

par(mfrow=c(2,1))
hist(S[,1],100)
hist(S[,2],100)

plot(S[,1],S[,2])
cor(S[,1],S[,2])

#save(claims.daily, fit1, fit2, lambda1s,lambda1w,lambda2s,lambda2w, file = "fitted.RData")
#save(S, file = "S.RData")

-------------------------------------------------------------------------------

## Risk och reserv Projekt 1
library(psych)

claims <- read.table("Projekt1_Grupp8.txt", header = TRUE, sep = ";")

# Olika vÃ¤rdedagar claim1 ? claim2 = inner join
CommonDays<-intersect(claims$ClaimDay[claims$ClaimType==1],
                      claims$ClaimDay[claims$ClaimType==2])

cost.daily <- aggregate(list(ClaimCost=claims$ClaimCost),
                        list(ClaimDay=claims$ClaimDay, ClaimType=claims$ClaimType), sum)

#Kontroll korrelation
D <- matrix(0,length(CommonDays),2)
for (k in 1:length(CommonDays))
{
  D[k,1]<-cost.daily$ClaimCost[cost.daily$ClaimDay==CommonDays[k] &
                               cost.daily$ClaimType==1]
  D[k,2]<-cost.daily$ClaimCost[cost.daily$ClaimDay==CommonDays[k] &
                               cost.daily$ClaimType==2]
}
rho.daily<-cor(D[,1],D[,2]) #= 0.2771018
plot(D[,1],D[,2],main=paste("rho.daily=",rho.daily))


# Yearly claim cost
claims.yearly <- claims
claims.yearly$ClaimYear <- (claims.yearly$ClaimDay %/% 366) + 1

cost.yearly <- aggregate(list(ClaimCost=claims.yearly$ClaimCost),
                         list(ClaimYear=claims.yearly$ClaimYear,
                              ClaimType=claims.yearly$ClaimType),
                         sum)

Y <- matrix(0,10,2)
for (k in 1:10)
{
  Y[k,1] <- cost.yearly$ClaimCost[cost.yearly$ClaimYear==k & cost.yearly$ClaimType==1]
  Y[k,2] <- cost.yearly$ClaimCost[cost.yearly$ClaimYear==k & cost.yearly$ClaimType==2]
}
rho.yearly<-cor(Y[,1],Y[,2]) #= 0.4308468
plot(Y[,1],Y[,2],main=paste("rho.yearly=",rho.yearly))


### Copulas

# Simulations of cost after 1 Y
# S1 Poisson/lognormal
# S2 Poisson/Weibull
load("S.RData")
#head(S,n=20)


n <- 100000
#rho<-0.5
# Create bivariate N[0,1]xN[0,1] w correlation rho
sigma <- matrix(c(1.0,  rho.yearly,
                  rho.yearly,  1.0), nrow=2)
x <- mvrnorm(n, mu=rep(0, 2), Sigma=sigma, empirical=TRUE)

# Transform to U[0,1]xU[0,1] u=F(x)
u <- pnorm(x)

# Inverse of empirical cdf from sampled marginaldistribution 
S1<-quantile(S[,1],u[,1],type=4)
S2<-quantile(S[,2],u[,2],type=4)


#save(S1,S2, file = "C.RData")

z<-cbind(S1,S2)
pairs.panels(z)

-----------------------------------------------------------------------------------------------------------------------------------------------------------


## Risk och reserv Projekt 1

### BOOTSTRAP

claims <- read.table("Projekt1_Grupp8.txt", header = TRUE, sep = ";")

claims.daily <- aggregate(list(ClaimCost=claims$ClaimCost),
                          list(ClaimDay=claims$ClaimDay,
                               ClaimType=claims$ClaimType), sum)
claims.daily$ClaimDay365 <- claims.daily$ClaimDay %% 365
claims.daily$ClaimDay365[claims.daily$ClaimDay365==0] <- 365

claims.daily$ClaimYear <- (claims.daily$ClaimDay%/%366) +1
claims.daily$ClaimMonth <- 0

months<-c(0,31,28,31,30,31,30,31,31,30,31,30,31)
months.cum<-cumsum(months)

for (m in 1:(length(months.cum)-1))
  claims.daily$ClaimMonth[months.cum[m] < claims.daily$ClaimDay365 &
                            claims.daily$ClaimDay365 <= months.cum[m+1]]<- m

cost.monthly<-aggregate(list(ClaimCost=claims.daily$ClaimCost),
                        list(ClaimYear=claims.daily$ClaimYear,
                             ClaimMonth=claims.daily$ClaimMonth,
                             ClaimType=claims.daily$ClaimType),
                        sum)

# Showing wintersummer
rho.ws <- cor(cost.monthly$ClaimCost[cost.monthly$ClaimType==1],
              cost.monthly$ClaimCost[cost.monthly$ClaimType==2])
plot(cost.monthly$ClaimCost[cost.monthly$ClaimType==1],
     cost.monthly$ClaimCost[cost.monthly$ClaimType==2],
     main=paste("rho=",rho.ws))


year <- unique(cost.monthly$ClaimYear)
month <- unique(cost.monthly$ClaimMonth)


tmp<-unique(cost.monthly[c("ClaimYear","ClaimMonth")])
tmp$Cost1 <- cost.monthly$ClaimCost[tmp$ClaimYear==cost.monthly$ClaimYear &
                                    tmp$ClaimMonth==cost.monthly$ClaimMonth &
                                    cost.monthly$ClaimType == 1]
tmp$Cost2 <- cost.monthly$ClaimCost[tmp$ClaimYear==cost.monthly$ClaimYear &
                                    tmp$ClaimMonth==cost.monthly$ClaimMonth &
                                    cost.monthly$ClaimType == 2]

winter.months<-c(1,2,3,4,9,10,11,12)
summer.months<-c(5,6,7)
# Winter
cost.winter<-subset(tmp, is.element(tmp$ClaimMonth, winter.months), 
                    select=c(Cost1,Cost2))
# Summer
cost.summer<-subset(tmp, is.element(tmp$ClaimMonth, summer.months), 
                    select=c(Cost1,Cost2))

n <- 1000
BS <- matrix(0,n,2)
for (k in 1:n)
{
  s.W<-tmp[sample(nrow(cost.winter),8, replace=TRUE),]
  s.S<-tmp[sample(nrow(cost.summer),4, replace=TRUE),]
  BS[k,1]<-sum(s.W$Cost1) + sum(s.S$Cost1)
  BS[k,2]<-sum(s.W$Cost2) + sum(s.S$Cost2)
}
rho.bs <- cor(BS[,1],BS[,2]) #= 0.8629129
plot(BS[,1],BS[,2],main=paste("rho=",rho.bs))

---------------------------------------------------------------------------------------------

## Risk och reserv Projekt 1

#save(S1,S2, file = "C.RData")
# Generated copula (S1,S2)
load("C.RData")

summary(S1)
# Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
# 64835115 69340476 70366080 70330397 71315888 75126283 
quantile(S1,0.5)
# 50% 
# 70366080
quantile(S1,c(0.1,0.5,0.9))
v <- (1:100)/100
plot(v,quantile(S1,v))

hist(S1+S2,100)

plot(v,quantile(S1+S2,v))

# SL-cover single
summary(S1+S2)
K <- quantile(S1+S2,0.9)

Rsl <- max(0,S1+S2-K)
price <- 1.1*mean(Rsl)





\end{verbatim}


\end{document}  